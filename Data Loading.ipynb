{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "from selenium.webdriver.common.by import By\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "chromedriver = \"chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(chromedriver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection check list\n",
    "* Rookie table (Player Name, Rookie Year, Position)\n",
    "* Salaries (Player Name, Year, Value)\n",
    "* Rookie stats(Player Name, Stats) (probably need to join)\n",
    "\n",
    "### HTML db\n",
    "* Rookie Links (Year, link, html)\n",
    "* Rookie Stats (Year, Name, link, html)\n",
    "\n",
    "### Nice to have\n",
    "* FansGraph stats\n",
    "* Cots detailed salary data (http://legacy.baseballprospectus.com/compensation/cots/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rookie table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pd_pkl(file):\n",
    "    import pandas as pd\n",
    "    try:\n",
    "        with open(f\"data/{file}.pkl\",'rb') as picklefile:\n",
    "            return pickle.load(picklefile)\n",
    "    except FileNotFoundError:\n",
    "        df = pd.read_csv(f\"{file}.csv\")\n",
    "        with open(f\"{file}.pkl\", 'wb') as picklefile:\n",
    "            pickle.dump(df, picklefile)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookie_df = load_pd_pkl('rookie_df')\n",
    "rookie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://www.baseball-reference.com/leagues/MLB/2012-rookies.shtml\"\n",
    "# url = \"https://www.baseball-reference.com/leagues/MLB/2012-rookies.shtml\"\n",
    "\n",
    "# driver.get(url)\n",
    "\n",
    "import re\n",
    "\n",
    "# p = re.complie('players')\n",
    "links = []\n",
    "for a in driver.find_elements_by_xpath('.//table/tbody/tr/td/a'):\n",
    "    \n",
    "    s = str(a.get_attribute('href'))\n",
    "#     print(s)\n",
    "    if re.search(r'players/.', s):\n",
    "        links.append(a.get_attribute('href'))\n",
    "len(links)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.baseball-reference.com/leagues/MLB/1992-rookies.shtml\"\n",
    "driver.get(url)\n",
    "# soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "# print(soup)\n",
    "for n in rookie_df.loc[rookie_df.rookie_year==1992,'Name']:\n",
    "    link = driver.find_element_by_link_text(n)\n",
    "    print(link.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rookie_pages(start, end, driver):\n",
    "    rookie_pages = pd.DataFrame(columns=['year','link','html'])\n",
    "    rookie_player_pages = pd.DataFrame(columns=['year','name','link','html'])\n",
    "    \n",
    "    #attempt to load from csv\n",
    "    try:\n",
    "        rookie_pages = pd.read_csv('data/rookie_pages.csv')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    print(rookie_pages.shape)\n",
    "    try:\n",
    "        rookie_player_pages = pd.read_csv('data/rookie_player_pages.csv')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    print(rookie_player_pages.shape)\n",
    "    \n",
    "    for i in range(start, end+1):\n",
    "        links_list = []\n",
    "        names_list = []\n",
    "        \n",
    "        #if year == i, then move onto link loop\n",
    "        if not (rookie_pages.year == i).any():\n",
    "            print('new rookie page data')\n",
    "            url = 'https://www.baseball-reference.com/leagues/MLB/'+str(i)+'-rookies.shtml'\n",
    "#             print('Scraping', url)\n",
    "            driver.get(url)\n",
    "            rookie_pages.loc[i] = [i, url, driver.page_source]\n",
    "\n",
    "            # scrape the rookie batters (includes pitchers if PA)\n",
    "            batting = driver.find_element_by_id('misc_batting') ## HTML tables\n",
    "            links = batting.find_elements_by_xpath('.//tbody/tr/td/a') ## player pages\n",
    "\n",
    "            # add these to the DF to save\n",
    "            links_list = [a.get_attribute('href') for a in links if re.search(r'players/.', a.get_attribute('href'))]\n",
    "            names_list = [a.text for a in links if re.search(r'players/.', a.get_attribute('href'))]\n",
    "\n",
    "            rookie_pages.to_csv('data/rookie_pages.csv')\n",
    "        \n",
    "        if len(links_list) != 0: # add new data\n",
    "            index = rookie_player_pages.index.max()+1\n",
    "            index_l = list(range(index, index+len(links_list)+1))\n",
    "            year_l = [i] * len(links_list)\n",
    "            rookie_player_pages.loc[index_l] = [year_l, names_list, links_list, np.nan()]\n",
    "\n",
    "        # loop only over incomplete data\n",
    "#         index = rookier_player_pages.index.max() + 1\n",
    "        \n",
    "        for l in rookie_player_pages.loc[(rookie_player_pages.html == np.nan), 'link'].values:\n",
    "            driver.get(l)\n",
    "#             print(names_list[k])\n",
    "            rookie_player_pages.loc[index, 'html'] = driver.page_source\n",
    "            if index != 0 and index % 10 == 0:\n",
    "                rookie_player_pages.to_csv('data/rookie_player_pages.csv')\n",
    "            index += 1\n",
    "        \n",
    "        rookie_player_pages.to_csv('data/rookie_player_pages.csv')\n",
    "\n",
    "    return rookie_pages, rookie_player_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n",
      "(157, 6)\n",
      "new rookie page data\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot set a row with mismatched columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-dae3580e7fab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# driver = webdriver.Chrome(chromedriver)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrookie_pages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrookie_player_pages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_rookie_pages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1998\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-a400043872b4>\u001b[0m in \u001b[0;36mbuild_rookie_pages\u001b[0;34m(start, end, driver)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#             print('Scraping', url)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mrookie_pages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# scrape the rookie batters (includes pitchers if PA)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    443\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                                 raise ValueError(\"cannot set a row with \"\n\u001b[0m\u001b[1;32m    446\u001b[0m                                                  \"mismatched columns\")\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot set a row with mismatched columns"
     ]
    }
   ],
   "source": [
    "# driver = webdriver.Chrome(chromedriver)\n",
    "rookie_pages, rookie_player_pages = build_rookie_pages(1998, 1999, driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookie_player_pages.to_csv('data/rookie_player_pages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookie_player_pages.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not (rookie_pages.year == 1998).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rookie_table(start, end, driver):\n",
    "    rookie_df = pd.DataFrame(columns=['Name','Debut','Age','Tm','rookie_year','links'])\n",
    "\n",
    "    for i in range(start, end+1):\n",
    "        url = 'https://www.baseball-reference.com/leagues/MLB/'+str(i)+'-rookies.shtml'\n",
    "        print('Scraping', url)\n",
    "        driver.get(url)\n",
    "\n",
    "        # scrape the rookie batters (includes pitchers if PA)\n",
    "        batting = driver.find_element_by_id('misc_batting') ## HTML tables\n",
    "        links = batting.find_elements_by_xpath('.//tbody/tr/td/a') ## player pages\n",
    "        links_list = [a.get_attribute('href') for a in links if re.search(r'players/.', a.get_attribute('href'))]\n",
    "        batting_df = pd.read_html(batting.get_attribute('outerHTML'))\n",
    "        \n",
    "        # add Name, Debut, Age, Tm, and rookie_year\n",
    "        year_df = batting_df[0].loc[:,['Name','Debut','Age','Tm']]\n",
    "        year_df['links'] = links_list\n",
    "        year_df['rookie_year'] = [i] * batting_df[0].shape[0]\n",
    "        year_df.rookie_year = year_df.rookie_year.astype(int)\n",
    "        rookie_df = rookie_df.append(year_df)\n",
    "        \n",
    "        # Strip HOF indicator from name\n",
    "        rookie_df.Name = rookie_df.Name.str.replace('HOF','')\n",
    "        rookie_df[rookie_df.Name.str.contains('HOF')]\n",
    "        rookie_df.Name = rookie_df.Name.str.strip()\n",
    "\n",
    "        \n",
    "        # build the player links\n",
    "        # build rookie_stats table\n",
    "        rookie_stats = pd.DataFrame(columns = ['Year', 'Age', 'Tm', 'Lg', 'G', 'PA', 'AB', 'R','H', 'SB','BA','HR','TB','2B','3B','RBI','BB','SO', 'position', 'name'])\n",
    "        for l in rookie_df.loc[(rookie_df.rookie_year == i), 'links'].values[:4]:\n",
    "            n = rookie_df.loc[rookie_df.links == l, 'Name'].values\n",
    "            print(n)\n",
    "#             link = driver.find_element_by_link_text(n)\n",
    "#             player_page = link.get_attribute('href')\n",
    "            \n",
    "#             driver.get(l)\n",
    "            \n",
    "#             print('Getting stats', n)\n",
    "#             player_df = get_player_data(driver, i, n)\n",
    "#             print('Completed', n)\n",
    "#             rookie_stats.append(player_df) \n",
    "        \n",
    "        #merge rookie_df and rookie_stats\n",
    "#         rookie_df = rookie_df.merge(rookie_stats, how='left',left_on=['Name','rookie_year'], right_on=['name','Year'])\n",
    "        \n",
    "        \n",
    "    return rookie_df#, rookie_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookie_df_1998, rookie_stats_1998 = build_rookie_table(1998, 1998, driver)\n",
    "# print(rookie_df_1998.shape)\n",
    "# print(len(links_list))\n",
    "# rookie_df_1998.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookie_df_1998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batting = driver.find_element_by_id('misc_batting')\n",
    "# links = batting.find_element_by_xpath('.//table/tbody/tr/td/a')\n",
    "# links_list = [a.get_attribute('href') for a in links]\n",
    "# batting_df = pd.read_html(batting.get_attribute('outerHTML'))\n",
    "print(batting.find_element_by_xpath('.//tbody/tr/td/a').get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_data(driver, year, name):\n",
    "\n",
    "    # Get position\n",
    "    position = driver.find_element_by_tag_name('p').text\n",
    "    position = position.split(':')[1].strip()\n",
    "#     print(position)\n",
    "\n",
    "    # Get batting stats\n",
    "    batting = driver.find_element_by_id('batting_standard')\n",
    "    batting_tbl_list = pd.read_html(batting.get_attribute('outerHTML'))\n",
    "    batting_df = batting_tbl_list[0]\n",
    "#     batting_df\n",
    "  \n",
    "    rookie_stats = batting_df[batting_df.Year == str(year)]\n",
    "    columns = ['Year', 'Age', 'Tm', 'Lg', 'G', 'PA', 'AB', 'R','H', 'SB','BA','HR','TB','2B','3B','RBI','BB','SO']\n",
    "    rookie_stats = rookie_stats.loc[:, columns]  \n",
    "    rookie_stats['position'] = position\n",
    "    rookie_stats['name'] = name\n",
    "    rookie_stats.Year = rookie_stats.Year.astype(int)\n",
    "\n",
    "    return rookie_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rookie_df.rookie_year = rookie_df.rookie_year.astype(int)\n",
    "# rookie_1998 = rookie_df[rookie_df.rookie_year == 1998]\n",
    "# rookie_1998 = rookie_1998.merge(rookie_stats, how='left',left_on=['Name','rookie_year'], right_on=['name','Year'])\n",
    "sub \n",
    "rookie_1998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookie_stats[rookie_stats.Year == '1998']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookie_stats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build URL list for rookie pages\n",
    "# build list of player URLs\n",
    "# navigate to URL\n",
    "# if pitcher ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookie_df = build_rookie_table(1985, 2017, driver)\n",
    "# rookie_df = pd.concat(rookie_df, rookie_year)\n",
    "rookie_df.head()\n",
    "# urls = build_rookie_urls(2012,2012)\n",
    "# driver.get(urls[0])\n",
    "# batting = driver.find_element_by_id('misc_batting')\n",
    "# batting_df = pd.read_html(batting.get_attribute('outerHTML'))\n",
    "# rookie_df = batting_df[0].loc[:,['Name','Debut','Age']]\n",
    "# rookie_df['rookie_year'] = [2012] * batting_df[0].shape[0]\n",
    "# rookie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookie_df.groupby('rookie_year').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookie_df['key'] = rookie_df.Name + rookie_df.Tm\n",
    "rookie_df.key.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookie_df[rookie_df.Name == 'Kevin Brown' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rookie_df = rookie_df.drop(columns='key')\n",
    "write_pkl(rookie_df, 'rookie_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rookie Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxscore_urls(driver):\n",
    "    urls = []\n",
    "    links = driver.find_elements_by_link_text('Boxscore')\n",
    "    for l in links:\n",
    "        urls.append(l.get_attribute('href'))\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = get_boxscore_urls(driver)\n",
    "print(urls[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the urls\n",
    "# loop through each url to render the page and get the tables\n",
    "#  Can i do this with pandas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def write_pkl(data,name):\n",
    "    with open('data/'+name+'.pkl', 'wb') as picklefile:\n",
    "        pickle.dump(data, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pkl(urls,'urls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls pickles/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all links by using find_elementS_by_link_text and loop\n",
    "hrefs = driver.find_element_by_link_text('Boxscore')\n",
    "hrefs.click()\n",
    "\n",
    "# scores = driver.find_elements_by_class_name('sortable stats_table now_sortable')\n",
    "# for s in scores[:4]:\n",
    "#     print(s.text)\n",
    "\n",
    "# go back when done getting the data and go to next link\n",
    "driver.back()\n",
    "# soup = BeautifulSoup(hrefs, 'lxml')\n",
    "# for h in hrefs:\n",
    "#     print(h.get_attribute('outerHTML'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tables and the first 4 elements have batting and pitching box scores\n",
    "# from selenium.webdriver.common.by import By\n",
    "driver.get(urls[0])\n",
    "scores = driver.find_elements(By.CSS_SELECTOR, '.sortable.stats_table.now_sortable')\n",
    "boxscore_htmls = []\n",
    "for s in scores[:4]:\n",
    "    boxscore_htmls.append(s.get_attribute('outerHTML'))\n",
    "\n",
    "boxscore_htmls\n",
    "# find_elements(by.CLASS_NAME())\n",
    "# driver.findElement(By.cssSelector(\".alert.alert-success\"));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the teams for the box score l[0] is the away team, 1[1] is the home team, l[2] is date\n",
    "import re\n",
    "teams = driver.find_element_by_tag_name('h1')\n",
    "print(re.split(r'at|Box Score,',teams.text))\n",
    "# for t in teams:\n",
    "#     print(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_html = pp_t.get_attribute('outerHTML')\n",
    "table_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_html(table_html)[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('br.html','w') as open_file:\n",
    "    open_file.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = response.text\n",
    "pages = pages.replace('<!--','')\n",
    "pages = pages.replace('-->','')\n",
    "# print(pages)\n",
    "soup = BeautifulSoup(pages, 'lxml')\n",
    "\n",
    "# print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find(class_='table_outer_container'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://www.baseball-reference.com/boxes/ATL/ATL201803290.shtml\"\n",
    "url = \"https://www.baseball-reference.com/leagues/MLB-schedule.shtml\"\n",
    "response = requests.get(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
